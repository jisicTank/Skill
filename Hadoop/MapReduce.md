# MapReduce

> 큰 데이터를 어디에 저장? -> HDFS
>
> 큰 데이터를 어떻게 처리? -> MapReduce

### MapReudce

> 대용량 데이터를 처리하기 위한 분산 프로그래밍 모델

<br>

- **맵리듀스 개념**

  - 맵리듀스 프레임워크를 이용해 대규모 분산 컴퓨팅 혹은 단일 컴퓨팅 환경에서 대량의 데이터를 병렬로 분석

  - 개발자가 맵리듀스 알고리즘에 맞게 분석 프로그램을 개발하면, 데이터의 입출력과 병렬 처리 등 기반 작업을 프레임워크가 알아서 처리해 줌

  - 맵리듀스 프로그래밍 모델은 단순하게 맵(Map)과 리듀스(Reduce)라는 두 개의 메서드로 구성

    ```
    맵: list(k1, v1) ==> list(k2, v2)
    
    리듀스: list(K2, list(v2)) ==> list(k3, v3)
    ```

    - 맵 메서드는 키(k1)와 값(v1)으로 구성된 데이터를 입력 받아, 이를 가공하고 분류한 후 새로운 키(k2)와 값(v2)으로 구성된 목록을 출력함
    - 이 때 맵 메서드가 반복해서 수행되다 보면 새로운 키(k2)를 가지는 여러 개의 데이터가 만들어짐. 새로운 키(K2)로 그룹핑된 값의 목록(list(v2))을 리듀스 메서드의 입력 데이터로 전달함
    - 리듀스 메서드는 값의 목록(list(v2))에 대한 집계 연산을 실행해 새로운 키(k3)와 값(v3)으로 구성된 목록을 생성함

  <br>

- **맵리듀스 시스템 구성**

  ![img](https://sites.google.com/site/medialoghadoop/_/rsrc/1439454096386/01-hadub-gicho/04-maeblidyuseu-sijaghagi/mapreduce_arche.jpg)

  - 맵리듀스 시스템은 **클라이언트, 잡트래커, 태스크트래커**로 구성됨. 다음 그림은 맵리듀스 시스템의 구성을 나타낸 것임 
    - 클라이언트: 사용자가 실행한 맵리듀스 프로그램과 하둡에서 제공하는 맵리듀스 API를 의미
    - 잡트래커: 하둡클러스터에 등록된 전체 잡의 스케줄링을 관리하고 모니터링
    - 태스크트래커: 데이터노드에서 실행되는 데몬이며, 잡트래커가 요청한 맵과 리듀스 개수만큼 맵 태스크와 리듀스 태스크를 생성함
  - 클라이언트가 하둡으로 실행을 요청하는 맵리듀스 프로그램을 **잡(job)**이라는 하나의 작업 단위로 관리함 
  - 전체 하둡 클러스터에서 하나의 잡트래커가 실행되며, 보통 네임노드 서버에서 실행됨
  - 사용자가 새로운 잡을 요청하면 잡트래커는 잡을 처리하기 위해 몇 개의 맵과 리듀스를 실행할지 계산함
  - 이렇게 계산된 맵과 리듀스를 어떤 태스크트래커에서 실행할지 결정하고, 해당 태스크트래커에 잡을 할당함
  - 맵 태스크와 리듀스 태스크가 생성되면 새로운 JVM을 구동해 맵 태스크와 리듀스 태스크를 실행함
  - 잡트래커와 태스크트래커는 하드비트라는 메서드로 네트워크 통신을 하면서 태스크트래커의 상태와 작업 실행 정보를 교환함
  - 만약 태스크트래커에 장애가 발생하면 잡트래커는 다른 대기 중인 태스크트래커를 찾아 태스크의 재실행을 요청함

  <br>

- **맵리듀스 처리 과정**

  - **input**: 보통 텍스트를 많이 처리하지만, 경우에 따라 이미지, 통계자료 등 여러가지가 입력데이터가 될 수 있다. 입력 파일은 HDFS에 적재되어 병렬처리를 위해 여러머신에 분배 된다.

  - **Splitting**: 입력한 파일 값을 `일반적으로` **개행문자[줄바꿈] 단위로 분할**

  - **Mapping**: 분할한 라인 단위 문장을 매퍼(Mapper)로 전달하면 매퍼의 맵함수는 입력 데이터를 원하는 키 Key-Value 형태로 만든다. 

    - 사용자가 원하는 Key-Value 형태를 만들기 위해 직접 코딩해야만 한다.
    - 매퍼는 입력 데이터의 크기에 따라서, 혹은 목적에 따라서 여러개가 존재할 수 있다. 

  - **컴바이너: Combiner**
    위의 맵리듀스 처리과정에서는 컴바이너를 사용하지 않았다. 맵리듀스 개념에서 리듀스가 `list(k2, list(v2))`로 되어있는 이유이기도 하다.

    - 컴파이너는 네트워크의 병목현상(Bottle-Neck) 을 줄일 수 있는 좋은 수단이다. 
    - 매퍼에서 출력된 Key-Value는 매우 난잡한 상황일것임에 틀림없다. 그 Key-Value를 하나로 뭉쳐서 리듀서로 보낼 때 적은 양의 데이터를 보낼 수 있도록 한다. 
    - **[사과, BlueApple] [바나나, Banana] [사과, RedApple] [사과, YellowApple]**   
      **-> 사과, {BlueApple, RedApple, YellowApple} ], [바나나, Banana]** 
    - 실제로 작업을 할 때에는 위와같이 적은 데이터가 아닌 어마어마하게 많은 Key-Value 쌍의 레코드들이 전송되기에, 이 작업은 매우 중요하다.
    -  각 매퍼에 하나의 컴바이너가 실행된다. 

  - **Shuffle, Partitioner**: 

    - Shuffle: 컴바이너에서 꾹꾹 담겨진 레코드들을 리듀서로 전송하는 일련의 과정을 '셔플' 이라고 한다. 
    - Partitioner: 파티셔너도 셔플에 포함된다고 보면 편한데, 실제로 존재하는 객체는 셔플이 아니라 파티셔너이다. 파티셔너는 각 매퍼에서 나온 출력 레코드들이 어느 리듀서로 가야할지를 정하는 작업이다. 
    - 매퍼 A와 B가 컴바이너를 거쳐서 나온 출력 레코드가 다음과 같다고 가정하자.

    ```
    매퍼 A : [사과, {BlueApple, RedApple, YellowApple} ], [바나나, Banana] 
    
    매퍼 B : [사과, {BlackApple} ], [바나나, {Banana, BlueBanana} ], [딸기, strawberry] 
    ```

    이제 위 데이터를 리듀서로 보내서 처리를 해야하는데, **같은 키를 가지는 레코드들은 같은 리듀서에서 처리되어야만 한다**. 그래야만 원하는 데이터를 얻어낼 수 있기 때문이다. 그럼 '사과' 라는 키를 가지는 레코드는 매퍼 A,B 말고도 매퍼 C,D에서도 나올텐데, 어떻게 하나의 리듀서로 보낼 수 있을까?

     **사과라는 키를 해시코드로 바꾼 뒤, 리듀서의 갯수로 그 해시코드를 나눠서 나온 나머지로 리듀서를 정한다**(뒤에서 설명하겠지만 리듀서 또한 사용자가 갯수를 지정할 수 있다).
    ![img](https://mblogthumb-phinf.pstatic.net/20150826_100/alice_k106_1440556884851u3OIT_PNG/%C4%B8%C3%B3.PNG?type=w2)

  - **Sort**: 리듀스 작업을 하기 전에 **정렬이라는 전처리 작업을 수행한다**. 리듀서에 도착한 레코드들을 **키값을 기준으로 정렬**한다. 그 이유는 매우 간단한데, **리듀스 작업을 용이하게 하기 위해**서이다.   
     위에서 든 예시에서 결국 2번 리듀서에 다음과 같은 레코드들이 도착했다고 가정하자.

    ```
    [사과, {BlueApple, RedApple, YellowApple} ] [바나나, Banana]  [사과, {BlackApple} ] [바나나, {Banana, BlueBanana} ]
    ```

     키가 사과인 레코드와 바나나인 레코드가 뒤섞여있다. 동일한 키에 대해 동일한 작업을 수행하기 위해서 키별로 모아야 하는데, 정렬을 통해 동일한 키를 가지는 레코드들을 한군데에 모은다. 그럼 리듀서 내부에서 다음과 같이 레코드들이 구성된다.

    ```
    사과 그룹 : [사과, {BlueApple, RedApple, YellowApple} ] [사과, {BlackApple} ]
    
    바나나 그룹 : [바나나, Banana] [바나나, {Banana, BlueBanana} ]
    ```

    

  - **Reduce**: 정렬을 통해 리듀서 내부에서 같은 키를 가지는 레코드들을 한군데에 모았다면, 리듀스 함수에서 그 한군데에 모아진 레코드들을 순서대로 처리할 수 있다.  
     예를 들어 리듀스 함수 내부에서 다음과 같은 로직으로 키:사과에 대한 레코드들의 value들을 출력할 수 있다. 출력 결과는 BlueApple, RedApple, YellowApple이 될 것이다.

    ![img](https://mblogthumb-phinf.pstatic.net/20150826_136/alice_k106_1440558599228duIzl_PNG/%25EC%25BA%25A1%25EC%25B2%2598.PNG?type=w800)
     키에 따라 모인 레코드들의 Value로 사용자가 원하는 작업을 하는 커스터마이징 작업을 거친다.  리듀서로 들어온 레코드들을 원하는 형태로 가공하여 결과 객체에 작성한 뒤 파일로 출력한다. 또한, 리듀서의 갯수를 사용자가 임의로 설정할 수 있기에, 다른 리듀서에서는 다른 과일(예를들면 키:딸기) 에 대한 작업이 이루어지고 있을지도 모른다.

  - **출력**:  각 리듀서마다 part-r-...... 의 포맷으로 결과를 출력한다. 예를들어 리듀서의 갯수가 3개라면 총 3개의 출력파일 : part-r-00001~03이 있을것이다.

  <br>

  ![image-20210408161909268](C:\Users\oh12s\Desktop\마크다운 이미지\image-20210408161909268.png)

- **다른예시: 단어 갯수 출력**

![img](https://t1.daumcdn.net/cfile/tistory/2133764B54F929D108)

- 맵리듀스의 장단점
  - 장점
    - 단순하고 사용이 편리
    - 특정 데이터 모델이나 스키마 정의, 질의 언어에 의존적이지 않아 비정형을 데이터 모델을 유연하게 지원 가능합니다.
    - 저장 구조와 독립적
    - 확장성이 높다
  - 단점
    - 복잡한 연산이 어려움
    - 기존 DBMS가 제공하는 스키마, 질의 언어, 인덱스 등의 기능을 지원하지 않습니다. 
    - DBMS와 비교하여 상대적으로 성능이 낮습니다. 예를 들면, 모든 Map과정이 진행될 때 까지 Reduce는 시작될 수 없습니다.
    - 처리속도 느림
    - 단순한 스케줄링

---

### Reference

- 맵리듀스 강의: https://www.youtube.com/watch?v=7XIHdbKfQ4Q&t=622s
- 맵리듀스 시스템 구성:https://sites.google.com/site/medialoghadoop/01-hadub-gicho/04-maeblidyuseu-sijaghagi
- 맵리듀스 시스템 구성-상세: https://tourspace.tistory.com/231
- 맵리듀스 처리과정: https://m.blog.naver.com/PostView.nhn?blogId=alice_k106&logNo=220462251435&proxyReferer=https:%2F%2Fwww.google.com%2F

